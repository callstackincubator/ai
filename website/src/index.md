---
pageType: home

hero:
  name: On-device LLMs in React Native
  text: 
  tagline: react-native-ai brings on-device LLMs capabilities to mobile React Native apps.
  actions:
    - theme: brand
      text: Quick Start
      link: /docs/
    - theme: alt
      text: GitHub
      link: https://github.com/callstackincubator/ai
  image:
    src:
      light: /logo-light.png
      dark: /logo-dark.png
    alt: Logo
features:
  - title: On-device LLM execution
    details: Run large language models directly on mobile devices without requiring cloud infrastructure or internet connectivity.
    icon: <img src="/device.svg" />
  - title: Vercel AI SDK compatibility
    details: Seamless integration with Vercel AI SDK, allowing you to use familiar functions like streamText and generateText with local models.
    icon: <img src="/code.svg" />
  - title: Apple Foundation Models
    details: Native support for Apple's Foundation Models on iOS 26+ devices with Apple Intelligence, providing seamless integration with Apple's on-device AI capabilities.
    icon: <img src="/apple.svg" />
  - title: MLC LLM Engine powered
    details: Built on top of MLC LLM Engine, providing optimized performance and efficient model execution on mobile devices.
    icon: <img src="/zap.svg" />
  - title: Cross-platform support
    details: Full support for both iOS and Android platforms with platform-specific optimizations and configurations.
    icon: <img src="/smartphone.svg" />
  - title: Privacy-first approach
    details: All AI processing happens locally on the device, ensuring user data privacy and eliminating the need for cloud-based AI services.
    icon: <img src="/shield.svg" />
---
